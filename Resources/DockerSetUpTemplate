#!/bin/bash

CURRENTUSER=$(whoami)
sudo rm -rf /home/$CURRENTUSER/.ssh/known_hosts
sudo rm -rf /root/.ssh/known_hosts
sudo rm -rf /root/.bash_history
sudo rm -rf /home/$CURRENTUSER/.bash_history

THEIP="THEREQIP"
THEHOST="THEREQHOSTNAME"
OS="THEREQOS"
DOCKER_DATA_DIR="THEREQDDD"
DFS_DATA_DIR="THEREQDFS"
DFS_DATA2_DIR="THEREQCD2FS"
DFS_CLUSTER_DIR="THEREQCDFS"
TLSSTUFF="THEREQTLS"
PortainerAPort="THEREQAPORT"
PortainerSPort="THEREQSPORT"
STACKNAME="THECURSTACK"
STACKPRETTYNAME="THECURPNSTACK"
STACKPRETTYNAME=$(echo "$STACKPRETTYNAME" | tr '[:upper:]' '[:lower:]')
SPNUPPER=$(echo "$STACKPRETTYNAME" | tr '[:lower:]' '[:upper:]')
VarahaPort1="VP1"
VarahaPort2="VP2"
VarahaPort3="VP3"
VarahaPort4="VP4"
TheReqRL="THEREQROLE"
BDD_PASSWORD="BDDPASSWORD"
BDDPort1="BDD1"
BDDPort2="BDD2"
BDD_HOSTS="BDDHOSTS"
CERTS_DIR="THECERTS"
ELIGIBLEFORVPN="GETVP"
BDD_CURRHOST="BDDCURRHOST"
websshPort1="WSP1"
webssh_PASSWORD="WSP2"
webssh_DIR="WSP3"
IDLE_LIMIT="WSP4"
THEVERWROUTER="WSP5"
THEVERW1ROUTER="WSP6"
CHITRAGUPTA="GGEPO"
REVERSED_PASSWORD="THEREVPWD"
	
sudo rm -rf /etc/hostname && echo "$THEHOST" | sudo tee /etc/hostname
sudo hostnamectl set-hostname $THEHOST --static
sudo hostnamectl set-hostname $THEHOST --transient
sudo hostnamectl set-hostname "$THEHOST" --pretty
sudo rm -f /opt/THEMENAME && sudo touch /opt/THEMENAME && echo "$THEHOST" | sudo tee -a /opt/THEMENAME > /dev/null && sudo chmod 777 /opt/THEMENAME

sudo rm -f /opt/DSUDONE$STACKNAME

if [[ "$CHITRAGUPTA" == "NA" ]]; then
	if [ "$TheReqRL" == "B" ] ; then
		echo "BRAHMA"
		sudo touch /opt/BRAHMA
		sudo chmod 777 /opt/BRAHMA				
	fi

	if [ "$TheReqRL" == "V" ] ; then
		echo "VISHVAKARMA"
		sudo touch /opt/VISHVAKARMA
		sudo chmod 777 /opt/VISHVAKARMA	
	fi

	if [ "$TheReqRL" == "I" ] ; then
		echo "INDRA"
		sudo touch /opt/INDRA
		sudo chmod 777 /opt/INDRA		
	fi	
else
	echo "CHITRAGUPTA"
	sudo touch /opt/CHITRAGUPTA
	sudo chmod 777 /opt/CHITRAGUPTA
fi

SetUpCHITRAGUPTA() {
	IFS='â– ' read -r -a CHITRAGUPTA_VAL <<< $CHITRAGUPTA
	CGLOGINDET="${CHITRAGUPTA_VAL[0]}"
	
	CGPORTSDET="${CHITRAGUPTA_VAL[1]}"		
	IFS=',' read -r -a CGPORTS_DET <<< "$CGPORTSDET"
	CG_PORTS_DET="${CGPORTS_DET[4]}"
	sudo firewall-cmd --zone=public --add-port=${CG_PORTS_DET}/tcp --permanent
	CG_PORTS2_DET="${CGPORTS_DET[5]}"
	sudo firewall-cmd --zone=public --add-port=${CG_PORTS2_DET}/tcp --permanent
	CG_PORTS3_DET="${CGPORTS_DET[6]}"
	sudo firewall-cmd --zone=public --add-port=${CG_PORTS3_DET}/tcp --permanent
		
	CGGUACAMOLEDET="${CHITRAGUPTA_VAL[2]}"
	IFS=',' read -r -a CGGUACAMOLE_DET <<< "$CGGUACAMOLEDET"
	V3="${CGGUACAMOLE_DET[0]}"
	V4="${CGGUACAMOLE_DET[1]}"
	V5="${CGGUACAMOLE_DET[2]}"
				
	CGMYSQLDET="${CHITRAGUPTA_VAL[3]}"
	IFS=',' read -r -a CGMYSQL_DET <<< "$CGMYSQLDET"
	V1="${CGMYSQL_DET[0]}"
	V2="${CGMYSQL_DET[1]}"
	IFS=':' read -r -a _V2 <<< "$V2"
	PGMEM="${_V2[0]}"
	PGCRS="${_V2[1]}"	
								
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/data
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/mysql 
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/mysql/schema 
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/guacamole 
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/data/mysql 
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/guacamoledata
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/guacddata
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpmyadmin
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/prometheus
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/grafana	
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/prometheusdata	
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/grafanadata
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/ldap	
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/ldif	
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/ldapdata	
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/ldapconfig
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/ldapcerts	
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpldapadmin
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/kerberos
	sudo mkdir -p $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/pvtcld
					
	sudo chown -R root:root $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME
	sudo chmod -R 777 $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME
	
	sudo chown -R 1000:1000 $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/guacamoledata
	sudo chmod -R 755 $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/guacamoledata

	echo "[libdefaults]
    default_realm = $SPNUPPER.VAMANA
    dns_lookup_realm = false
    dns_lookup_kdc = false

[realms]
    $SPNUPPER.VAMANA = {
        kdc = kerberos.$STACKPRETTYNAME.vamana
        admin_server = kerberos.$STACKPRETTYNAME.vamana
    }

[domain_realm]
    .$STACKPRETTYNAME.vamana = $SPNUPPER.VAMANA
    $STACKPRETTYNAME.vamana = $SPNUPPER.VAMANA
" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/kerberos/krb5.conf > /dev/null
	echo "[kdcdefaults]
    kdc_ports = 88

[realms]
    $SPNUPPER.VAMANA = {
        database_name = /var/lib/krb5kdc/principal
        admin_keytab = FILE:/etc/krb5kdc/kadm5.keytab
        acl_file = /etc/krb5kdc/kadm5.acl
        dict_file = /usr/share/dict/words
        key_stash_file = /etc/krb5kdc/stash
        kdc_ports = 88
        max_life = 10h 0m 0s
        max_renewable_life = 7d 0h 0m 0s
        default_principal_flags = +preauth
    }
" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/kerberos/kdc.conf > /dev/null
	echo "*/admin@$SPNUPPER.VAMANA *
" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/kerberos/kadm5.acl > /dev/null
		
	echo "dn: cn=users,ou=groups,dc=$STACKPRETTYNAME,dc=vamana
objectClass: top
objectClass: posixGroup
cn: users
gidNumber: 1000

dn: cn=admins,ou=groups,dc=$STACKPRETTYNAME,dc=vamana
objectClass: top
objectClass: posixGroup
cn: admins
gidNumber: 1001" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/ldif/groups.ldif > /dev/null

	echo "global:
  scrape_interval:     15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['prometheus:9090']

  - job_name: 'cadvisor'
    dns_sd_configs:
    - names:
      - 'tasks.cadvisor'
      type: 'A'
      port: 8080

  - job_name: 'node-exporter'
    dns_sd_configs:
    - names:
      - 'tasks.node-exporter'
      type: 'A'
      port: 9100" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/prometheus/prometheus.yml > /dev/null

	sudo mv /home/$CURRENTUSER/EnablePvtCldShare.sh $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/pvtcld/EnablePvtCldShare.sh
	sudo chmod 777 $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/pvtcld/EnablePvtCldShare.sh
	sudo mv /home/$CURRENTUSER/EnablePvtCldShare2.sh $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/pvtcld/EnablePvtCldShare2.sh
	sudo chmod 777 $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/pvtcld/EnablePvtCldShare2.sh	
	sudo mv /home/$CURRENTUSER/EnablePvtCldShare3.sh $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/pvtcld/EnablePvtCldShare3.sh
	sudo chmod 777 $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/pvtcld/EnablePvtCldShare3.sh	
	sudo mv /home/$CURRENTUSER/1860_rev37.json $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/grafana/dashboard.json
	sudo mv /home/$CURRENTUSER/container-metrics.json $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/grafana/container-metrics.json
	sudo mv /home/$CURRENTUSER/node-metrics.json $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/grafana/node-metrics.json
	echo "apiVersion: 1
datasources:
  - name: Prometheus_$STACKPRETTYNAME
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    uid: PBFA97CFB590B2093
" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/grafana/datasource.yml > /dev/null

	echo "apiVersion: 1
providers:
  - name: 'Monitoring_$STACKPRETTYNAME'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    options:
      path: /etc/grafana/provisioning/dashboards
" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/grafana/dashboard.yml > /dev/null

	sudo cp /home/$CURRENTUSER/boodark.tar.gz $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpldapadmin
	pushd $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpldapadmin
	sudo chmod 777 boodark.tar.gz
	tar -xzf "boodark.tar.gz"
	sudo rm -f boodark.tar.gz
	sudo chmod -R 777 boodark	
	popd
	echo '<?php
$cfg['"'"'ThemeDefault'"'"'] = '"'"'boodark'"'"';' | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpldapadmin/config.user.inc.php > /dev/null

	sudo mv /home/$CURRENTUSER/boodark.tar.gz $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpmyadmin
	pushd $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpmyadmin
	sudo chmod 777 boodark.tar.gz
	tar -xzf "boodark.tar.gz"
	sudo rm -f boodark.tar.gz
	sudo chmod -R 777 boodark	
	popd
	echo '<?php
$cfg['"'"'ThemeDefault'"'"'] = '"'"'boodark'"'"';' | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/phpmyadmin/config.user.inc.php > /dev/null
	
	sudo mv /home/$CURRENTUSER/initdb-redux.sql $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/mysql/schema
	
	echo "[mysqld]
innodb_buffer_pool_size = 1G
innodb_log_file_size = 256M
innodb_log_buffer_size = 64M
innodb_flush_log_at_trx_commit = 1
sync_binlog = 1
max_connections = 500
query_cache_type = 1
query_cache_size = 128M
key_buffer_size = 64M
thread_cache_size = 50
tmp_table_size = 64M
max_heap_table_size = 64M" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/mysql/my.cnf > /dev/null

	echo "mysql-hostname: mysql
mysql-port: 3306
mysql-database: $V3
mysql-username: $V4
mysql-password: $V5
guacd-hostname: guacd
guacd-port: 4822" | tee $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/guacamole/guacamole.properties > /dev/null

	echo "CREATE DATABASE $V3;
CREATE USER '$V4'@'%' IDENTIFIED BY '$V5';
GRANT SELECT,INSERT,UPDATE,DELETE ON $V3.* TO '$V4'@'%';
FLUSH PRIVILEGES;" > $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME/mysql/initdb.sql
	
	sudo chown -R root:root $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME
	sudo chmod -R 777 $DFS_DATA_DIR/CHITRAGUPTA$STACKNAME
	
	echo "ServerName $THEHOST" | tee $DFS_DATA_DIR/Misc$STACKNAME/custom-apache-config.conf > /dev/null
	sudo mv /home/$CURRENTUSER/config.php $DFS_DATA_DIR/Misc$STACKNAME/config.php
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/custom-apache-config.conf
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/config.php
	
	CGV8DET="${CHITRAGUPTA_VAL[8]}"		
	IFS=',' read -r -a CGV8_DET <<< "$CGV8DET"	
	CG_V8_1="${CGV8_DET[1]}"
	CG_V8_11="${CGV8_DET[11]}"	
	sudo firewall-cmd --zone=public --permanent --add-rich-rule='rule family="ipv4" source address="'"$CG_V8_11"'" port port="'"$CG_V8_1"'" protocol="tcp" accept'
	sudo firewall-cmd --zone=public --permanent --add-rich-rule='rule family="ipv4" port port="'"$CG_V8_1"'" protocol="tcp" reject'
	sudo firewall-cmd --reload		
}

# Function to check and remove lock files
remove_locks() {
    echo "Checking and removing lock files..."
    sudo rm -f /var/lib/dpkg/lock-frontend
    sudo rm -f /var/lib/dpkg/lock
}

# Function to check and terminate running apt or dpkg processes
terminate_processes() {
    echo "Checking for running apt or dpkg processes..."
    pids=$(ps aux | grep -E 'apt|dpkg' | grep -v grep | awk '{print $2}')
    if [ -z "$pids" ]; then
        echo "No running apt or dpkg processes found."
    else
        echo "Terminating running apt or dpkg processes..."
        for pid in $pids; do
            sudo kill -9 $pid
            echo "Terminated process with PID: $pid"
        done
    fi
}

# Function to reconfigure dpkg
reconfigure_dpkg() {
    echo "Reconfiguring dpkg..."
    sudo dpkg --configure -a
}

# Function to update package list
update_package_list() {
    echo "Updating package list..."
    sudo apt-get update -y
}

remove_locks
terminate_processes
remove_locks
reconfigure_dpkg
update_package_list
echo "System is ready for package installation..."

create_webssh_manager_support_files() {
	echo '#!/bin/bash

IP=$1
HASH=$2

first_port=35000
last_port=65000

function random_unused_port {
    local port=$(shuf -i $first_port-$last_port -n 1)
    # Check if the port is being used
    if ! ss -ltn | grep -q ":$port " ; then
        echo $port
        return 0
    else
        random_unused_port
    fi
}

PORT=$(random_unused_port)

thereqip=$(awk -F '"'"','"'"' '"'"'$1 == "$IP" {print; exit}'"'"' "'"$webssh_DIR"'/.Nodes")
IFS='"'"','"'"' read -r -a the_reqip <<< $thereqip
rt1pem="${the_reqip[2]}"
rt1realpem="${rt1pem##*/}"
rt1real2pem="'"$webssh_DIR"'/PEMS/$rt1realpem"
THE1USER="${the_reqip[3]}"
PO1RT="${the_reqip[1]}"

echo "sh '"$webssh_DIR"'/custom_ssh.sh $IP $HASH $rt1real2pem $THE1USER $PO1RT"

# Create a dynamic docker-compose file
cat <<EOF > '"$DFS_DATA_DIR/Tmp$STACKNAME"'/websshDockerCompose$HASH.yml
version: '"'"'3.7'"'"'

services:
  wetty:
    image: webssh'"$STACKPRETTYNAME"'
    command: "sh '"$webssh_DIR"'/custom_ssh.sh $IP $HASH $rt1real2pem $THE1USER $PO1RT"
    ports:
      - "$PORT:3000"
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.labels.'"$STACKNAME"'routerreplica == true 
      restart_policy:
        condition: none               
    volumes:
      - type: bind
        source: '"$webssh_DIR"'
        target: '"$webssh_DIR"'
    networks:
      - '"$STACKNAME"'-encrypted-overlay

networks:
  '"$STACKNAME"'-encrypted-overlay:
    external: true
EOF

therouter=$(awk -F '"'"','"'"' '"'"'$8 == "ROUTER" {print; exit}'"'"' "'"$webssh_DIR"'/.Nodes")
hostname=$(awk -F '"'"','"'"' '"'"'$8 == "ROUTER" {print $5; exit}'"'"' "'"$webssh_DIR"'/.Nodes")

IFS='"'"','"'"' read -r -a the_router <<< $therouter
rtip="${the_router[0]}"
rtpem="${the_router[2]}"
rtrealpem="${rtpem##*/}"
rtreal2pem="'"$webssh_DIR"'/PEMS/$rtrealpem"
sudo chmod 400 $rtreal2pem
rtuser="${the_router[3]}"
rtport="${the_router[1]}"

sudo touch '"$DFS_DATA_DIR/Tmp$STACKNAME"'/$HASH.url && sudo chmod 777 '"$DFS_DATA_DIR/Tmp$STACKNAME"'/$HASH.url && echo "https://$hostname:'"$websshPort1"'/wetty/$HASH" | sudo tee -a '"$DFS_DATA_DIR/Tmp$STACKNAME"'/$HASH.url > /dev/null

# Run the Docker container using Docker Compose on the worker node
docker stack deploy --compose-file '"$DFS_DATA_DIR/Tmp$STACKNAME"'/websshDockerCompose$HASH.yml webssh$HASH
		
# Update HAProxy configuration using Runtime API
ssh -i "$rtreal2pem" -o StrictHostKeyChecking=no -p $rtport $rtuser@$rtip "'"$webssh_DIR"'/update_haproxy.sh $HASH $PORT"
' | tee $webssh_DIR/StartContainerwebssh.sh > /dev/null
	chmod +x $webssh_DIR/StartContainerwebssh.sh
}
create_webssh_router_support_files() {
	echo '#!/bin/bash

HASH=$1
PORT=$2

# Determine the IP address of the Docker bridge interface (docker0)
THEROUTER=$(ip addr show docker0 | grep '"'inet '"' | awk '"'"'{print $2}'"'"' | cut -d'"'"'/'"'"' -f1)

# Add new mapping to '"$STACKPRETTYNAME"'backend.map
echo "/wetty/$HASH '"$STACKPRETTYNAME"'_WebSSH_Back" >> '"$webssh_DIR"'/'"$STACKPRETTYNAME"'backend.map

# Use the HAProxy Runtime API to add the new server to the backend
echo "add server '"$STACKPRETTYNAME"'_WebSSH_Back/wetty-$HASH $THEROUTER:$PORT check"
echo "add server '"$STACKPRETTYNAME"'_WebSSH_Back/wetty-$HASH $THEROUTER:$PORT check" | sudo socat stdio '"$DFS_DATA_DIR/Misc$STACKNAME"'/RunHAProxy/'"$STACKPRETTYNAME"'admin.sock
echo "enable server '"$STACKPRETTYNAME"'_WebSSH_Back/wetty-$HASH" | sudo socat stdio '"$DFS_DATA_DIR/Misc$STACKNAME"'/RunHAProxy/'"$STACKPRETTYNAME"'admin.sock
' | tee $webssh_DIR/update_haproxy.sh > /dev/null
	chmod +x $webssh_DIR/update_haproxy.sh
	
	echo '#!/bin/sh

HASH=$1

LOGFILE="'"$webssh_DIR"'/inactivity_check_'"$STACKPRETTYNAME"'-$HASH.log"
IDLE_LIMIT='"$IDLE_LIMIT"'  # Idle limit in seconds

echo "$(date): Starting inactivity check script" >> $LOGFILE

while true; do
    # Get the last activity time of the tmux session
    LAST_ACTIVITY=$(tmux display -p -t $HASH '"'#{client_activity}'"')
    CURRENT_TIME=$(date +%s)

    # Calculate the idle time
    IDLE_TIME=$((CURRENT_TIME - LAST_ACTIVITY))

    echo "$(date): Current time: $CURRENT_TIME, Last activity: $LAST_ACTIVITY, Idle time: $IDLE_TIME" >> $LOGFILE

    if [ "$IDLE_TIME" -gt "$IDLE_LIMIT" ]; then
        echo "$(date): Container idle for more than $IDLE_LIMIT seconds. Exiting." >> $LOGFILE
        kill 1  # Send SIGTERM to PID 1 to stop the container
        exit
    fi

    sleep 60  # Check every 60 seconds
done' | tee $webssh_DIR/inactivity_check.sh > /dev/null
	chmod +x $webssh_DIR/inactivity_check.sh
	
	echo '#!/bin/bash

IP="$1"
HASH="$2"
PEM_FILE="$3"
THEUSER="$4"
PORT="$5"

LOGFILE="'"$webssh_DIR"'/custom_ssh_'"$STACKPRETTYNAME"'-$HASH.log"
echo "$(date): Starting custom_ssh_ script IP : $IP HASH : $HASH PEM_FILE : $PEM_FILE THEUSER : $THEUSER PORT : $PORT" >> $LOGFILE

if [ -f "$PEM_FILE" ]; then
    echo "$(date): custom_ssh_ script came here1" >> $LOGFILE
    tmux new-session -d -s $HASH "ssh -i "$PEM_FILE" -o StrictHostKeyChecking=no -p "$PORT" $THEUSER@$IP"
    echo "$(date): custom_ssh_ script came here2" >> $LOGFILE
    '"$webssh_DIR"'/inactivity_check.sh "$HASH" &
    echo "$(date): custom_ssh_ script came here3" >> $LOGFILE
    tmux attach-session -t $HASH
    echo "$(date): custom_ssh_ script came here4" >> $LOGFILE
else
    echo "PEM file for $IP not found."
    echo "$(date): custom_ssh_ script came here5" >> $LOGFILE
    exit 1
fi' | tee $webssh_DIR/custom_ssh.sh > /dev/null
	chmod +x $webssh_DIR/custom_ssh.sh
		
	echo 'FROM '"$THEVERW1ROUTER"':'"$THEVERWROUTER"'

# Install tmux
RUN apk update && apk add tmux

# Copy custom scripts
COPY custom_ssh.sh '"$webssh_DIR"'/custom_ssh.sh
COPY inactivity_check.sh '"$webssh_DIR"'/inactivity_check.sh

# Make scripts executable
RUN chmod +x '"$webssh_DIR"'/custom_ssh.sh '"$webssh_DIR"'/inactivity_check.sh' | tee $webssh_DIR/webssh.Dockerfile > /dev/null
	cd $webssh_DIR
	sudo docker build -t webssh$STACKPRETTYNAME -f webssh.Dockerfile .
	cd ~			
}

setup_http_server() {
    sudo mkdir -p $DFS_DATA2_DIR/Static$STACKNAME
    sudo chown -R root:root $DFS_DATA2_DIR/Static$STACKNAME
    sudo rm -f $DFS_DATA2_DIR/Static$STACKNAME/Index.html
    echo "VARAHA For $STACKPRETTYNAME" | sudo tee $DFS_DATA2_DIR/Static$STACKNAME/Index.html
    sudo chmod -R 777 $DFS_DATA2_DIR/Static$STACKNAME
    
    sudo rm -f /etc/systemd/system/VARAHA$STACKNAME.service
    
    SERVICES=$(systemctl list-units --type=service --state=running | grep 'VARAHA' | awk '{print $1}')
    if [ -z "$SERVICES" ]; then
        echo "No services starting with VARAHA found."
    fi
    for service in $SERVICES; do
        echo "Stopping and disabling $service..."
        sudo systemctl stop "$service"
        sudo systemctl disable "$service"
        echo "$service stopped and disabled."
    done    
    
    echo '[Unit]
Description=VARAHA For '"$STACKPRETTYNAME"'
After=network.target

[Service]
User=root
WorkingDirectory='"$DFS_DATA2_DIR/Static$STACKNAME"'
ExecStart=/usr/bin/python3 -m http.server '"$VarahaPort1"'
Restart=always

[Install]
WantedBy=multi-user.target' | sudo tee /etc/systemd/system/VARAHA$STACKNAME.service > /dev/null

    sudo systemctl daemon-reload
    sudo systemctl enable VARAHA$STACKNAME
    sudo systemctl start VARAHA$STACKNAME
}

create_error_files() {
    sudo mkdir -p $DFS_DATA_DIR/Errors$STACKNAME
    sudo rm -f $DFS_DATA_DIR/Errors$STACKNAME/*.http
    
    cat <<EOF > $DFS_DATA_DIR/Errors$STACKNAME/400.http
HTTP/1.0 400 Bad Request
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body><h1>400 Bad Request</h1>
Your browser sent a request that this server could not understand.<br />
</body></html>
EOF

    cat <<EOF > $DFS_DATA_DIR/Errors$STACKNAME/403.http
HTTP/1.0 403 Forbidden
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body><h1>403 Forbidden</h1>
You don't have permission to access this resource.<br />
</body></html>
EOF

    cat <<EOF > $DFS_DATA_DIR/Errors$STACKNAME/408.http
HTTP/1.0 408 Request Timeout
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body><h1>408 Request Timeout</h1>
Your browser sent a request that this server could not understand.<br />
</body></html>
EOF

    cat <<EOF > $DFS_DATA_DIR/Errors$STACKNAME/500.http
HTTP/1.0 500 Internal Server Error
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body><h1>500 Internal Server Error</h1>
The server encountered an internal error or misconfiguration and was unable to complete your request.<br />
</body></html>
EOF

    cat <<EOF > $DFS_DATA_DIR/Errors$STACKNAME/502.http
HTTP/1.0 502 Bad Gateway
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body><h1>502 Bad Gateway</h1>
The server received an invalid response from the upstream server.<br />
</body></html>
EOF

    cat <<EOF > $DFS_DATA_DIR/Errors$STACKNAME/503.http
HTTP/1.0 503 Service Unavailable
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body><h1>503 Service Unavailable</h1>
The server is currently unable to handle the request due to a temporary overload or maintenance.<br />
</body></html>
EOF

    cat <<EOF > $DFS_DATA_DIR/Errors$STACKNAME/504.http
HTTP/1.0 504 Gateway Timeout
Cache-Control: no-cache
Connection: close
Content-Type: text/html

<html><body><h1>504 Gateway Timeout</h1>
The server did not receive a timely response from the upstream server.<br />
</body></html>
EOF

sudo chown -R root:root $DFS_DATA_DIR/Errors$STACKNAME
sudo chmod -R 777 $DFS_DATA_DIR/Errors$STACKNAME
}

disable_selinux_temporary() {
    echo "Current SELinux status:"
    sestatus | grep "SELinux status:"

    sudo setenforce 0
    sudo -H -u root bash -c 'setenforce 0'
    
    echo "Updated SELinux status (temporary):"
    sestatus | grep "SELinux status:"
}

disable_selinux_permanent() {
    sudo sed -i 's/^SELINUX=.*/SELINUX=disabled/g' /etc/selinux/config

    echo "SELinux permanently disabled in /etc/selinux/config:"
    grep "^SELINUX=" /etc/selinux/config
}

install_firewalld() {
    remove_locks
    terminate_processes
    remove_locks
    reconfigure_dpkg
    update_package_list
    echo "System is ready for package installation..."
    echo "Installing firewalld..."
    if [[ "$OS" == "UBU" ]]; then
        sudo NEEDRESTART_MODE=a $PKG_MANAGER install -y firewalld    
    else
        sudo $PKG_MANAGER install -y firewalld
    fi
    sudo systemctl start firewalld
    sudo systemctl enable firewalld
    echo "Configuring firewall rules explicitly in the public zone..."
    sudo firewall-cmd --zone=public --permanent --add-service=ssh
    sudo firewall-cmd --zone=public --permanent --add-service=http
    sudo firewall-cmd --zone=public --permanent --add-service=https
    sudo firewall-cmd --reload
}

install_python() {
	echo "Installing Python3 and pip..."
	if [[ "$OS" == "UBU" ]]; then
	remove_locks
	terminate_processes
	remove_locks
	reconfigure_dpkg
	update_package_list
	echo "System is ready for package installation..."    
        #sudo rm -f /var/lib/dpkg/lock-frontend
        #sudo rm -f /var/cache/apt/archives/lock
        #sudo rm -f /var/lib/dpkg/lock-frontend
        #sudo rm -f /var/cache/apt/archives/lock        
        sudo NEEDRESTART_MODE=a $PKG_MANAGER install -y python3 python3-pip  
        #sudo rm -f /var/cache/apt/archives/lock 
        sudo NEEDRESTART_MODE=a $PKG_MANAGER install -y python3 python3-pip         
    else
        sudo $PKG_MANAGER install -y python3 python3-pip 
    fi
}

install_minio() {
	sudo chmod 777 /home/$CURRENTUSER/mc
	sudo rm -f /usr/bin/mc
	sudo mv /home/$CURRENTUSER/mc /usr/bin
	
	sudo mkdir -p /shiva/bdd/bucket && sudo chown -R root:root /shiva/bdd/bucket && sudo chmod -R u=rwx,g=rwx,o=rwx /shiva/bdd/bucket
	sudo mkdir -p /shiva/bdd/bucket/$STACKNAME && sudo chown -R root:root /shiva/bdd/bucket/$STACKNAME && sudo chmod -R u=rwx,g=rwx,o=rwx /shiva/bdd/bucket/$STACKNAME
		
	sudo mkdir -p $DFS_DATA_DIR/MINIO
	sudo chown -R root:root $DFS_DATA_DIR/MINIO
	sudo chmod -R 777 $DFS_DATA_DIR/MINIO
	sudo mkdir -p $DFS_DATA_DIR/MINIODATA
	sudo chown -R root:root $DFS_DATA_DIR/MINIODATA
	sudo chmod -R 777 $DFS_DATA_DIR/MINIODATA
	sudo mkdir -p $DFS_DATA_DIR/miniogdata
	sudo chown -R root:root $DFS_DATA_DIR/miniogdata
	sudo chmod -R 777 $DFS_DATA_DIR/miniogdata
		
	pushd $DFS_DATA_DIR/MINIO		
	echo "admin:$REVERSED_PASSWORD" | tee .$STACKPRETTYNAME > /dev/null
	echo '#!/bin/sh

# Get the current list of Minio nodes
#MINIO_SERVER_URLS=$(nslookup tasks.minio | grep Address | awk '"'"'{ print $3 }'"'"' | grep -v '"'"'127.0.0.11'"'"' | sed '"'"'s/$/:9000/'"'"' | paste -sd "," -)

# Start Minio server with dynamically generated MINIO_SERVER_URLS
#exec minio server --address :9000 --console-address :9001 $MINIO_SERVER_URLS
exec minio server /data --address :9000 --console-address :9001' | tee EntryPoint.sh > /dev/null
	sudo chmod 777 EntryPoint.sh
	sudo mv /home/$CURRENTUSER/MountSBB.sh .
	sudo chmod 777 MountSBB.sh
	
	echo '{
  "port": 80,
  "address": "",
  "log": "stdout",
  "database": "/database/filebrowser.db",
  "root": "/srv",
  "auth": {
    "method": "password",
    "password": "'"$REVERSED_PASSWORD"'"
  }
}' | tee filebrowser.json > /dev/null
	popd
	
	sudo mkdir -p $DFS_DATA_DIR/NEXTCLOUD
	sudo chown -R root:root $DFS_DATA_DIR/NEXTCLOUD
	sudo chmod -R 777 $DFS_DATA_DIR/NEXTCLOUD
	sudo mkdir -p $DFS_DATA_DIR/nextgcloud
	sudo chown -R root:root $DFS_DATA_DIR/nextgcloud
	sudo chmod -R 777 $DFS_DATA_DIR/nextgcloud
	
	sudo mv /home/$CURRENTUSER/SetUpKerberos.sh $DFS_DATA_DIR/Misc$STACKNAME
	sudo chmod 777 $DFS_DATA_DIR/Misc$STACKNAME/SetUpKerberos.sh						
}

THEOSCHOICE="NA"

if [ ! -f /opt/CLD ]; then
	echo 'ON PREMISE'
else
	THEOSCHOICE=$(head -n 1 /opt/CLD)
	
	if [ ! -f /opt/LCL ] || [ ! -f /opt/GBL ]; then
	    echo "One or both files do not exist."
	    exit 1
	else
	    echo "Both files exist."
	fi

	if [[ "$THEOSCHOICE" == "AWS_UBU" ]]; then
		LCLVAL=$(head -n 1 /opt/LCL)
		GBLVAL=$(head -n 1 /opt/GBL)
		SOFTVAL="Y"
		FILEVAL="Y"
		if ! which s3fs >/dev/null || ! which aws >/dev/null; then
		    SOFTVAL="N"
		fi
		if [ ! -f "/shiva/local/bucket/$LCLVAL" ] || [ ! -f "/shiva/global/bucket/$GBLVAL" ]; then
		    FILEVAL="N"
		fi
		if [ "$SOFTVAL" = "N" ] || [ "$FILEVAL" = "N" ]; then
		    if [ -f /opt/EXEC1ON ]; then
			sleep 15
			/opt/EXEC1ON
		    elif [ -f /opt/EXEC1DONE ]; then
			sudo mv /opt/EXEC1DONE /opt/EXEC1ON
			/opt/EXEC1ON
		    fi
		fi	
		DNS_NAME_FILE="/opt/EDN"
		EFS_DNS_NAME=$(cat "$DNS_NAME_FILE")
		MOUNT_POINT="/shiva/global/storage"
		sudo mount -t nfs4 -o nfsvers=4.1 "$EFS_DNS_NAME":/ "$MOUNT_POINT"	
		INTERNALIP=$(ip addr show eth0 | grep 'inet ' | awk '{print $2}' | cut -d'/' -f1)
		sudo rm -f /opt/WHOAMI2 && sudo touch /opt/WHOAMI2 && sudo chmod 777 /opt/WHOAMI2 && echo "$INTERNALIP" | sudo tee -a /opt/WHOAMI2 > /dev/null
	fi

	if [[ "$THEOSCHOICE" == "GCP_UBU" ]]; then
		INTERNALIP=$(ip addr show ens4 | grep 'inet ' | awk '{print $2}' | cut -d'/' -f1)
		sudo rm -f /opt/WHOAMI2 && sudo touch /opt/WHOAMI2 && sudo chmod 777 /opt/WHOAMI2 && echo "$INTERNALIP" | sudo tee -a /opt/WHOAMI2 > /dev/null
		
		LCLVAL=$(head -n 1 /opt/LCL)
		GBLVAL=$(head -n 1 /opt/GBL)
		SOFTVAL="Y"
		FILEVAL="Y"
		if ! which gcsfuse >/dev/null || ! which gcsfuse >/dev/null; then
		    SOFTVAL="N"
		fi
		if [ ! -f "/shiva/local/bucket/$LCLVAL" ] || [ ! -f "/shiva/global/bucket/$GBLVAL" ]; then
		    FILEVAL="N"
		fi
		if [ "$SOFTVAL" = "N" ] || [ "$FILEVAL" = "N" ]; then
		    if [ -f /opt/EXEC1ON ]; then
			sleep 5
			/opt/EXEC1ON
		    elif [ -f /opt/EXEC1DONE ]; then
			sudo mv /opt/EXEC1DONE /opt/EXEC1ON
			sudo rm -f /etc/apt/sources.list.d/gcsfuse.list
			sudo rm -f /usr/share/keyrings/cloud.google.asc
			echo "deb [signed-by=/usr/share/keyrings/cloud.google.asc] https://packages.cloud.google.com/apt gcsfuse-jammy main" | sudo tee /etc/apt/sources.list.d/gcsfuse.list > /dev/null
			curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo tee /usr/share/keyrings/cloud.google.asc
			sudo apt-get update -y
			sudo apt-get install gcsfuse -y
			sudo gcsfuse --file-mode 777 --dir-mode 777 $LCLVAL "/shiva/local/bucket"
			sudo gcsfuse --file-mode 777 --dir-mode 777 $GBLVAL "/shiva/global/bucket"
			sudo touch /shiva/local/bucket/$LCLVAL
			sudo touch /shiva/global/bucket/$GBLVAL
			sudo mv /opt/EXEC1ON /opt/EXEC1DONE
		    fi
		fi		
	fi
		
	if [[ "$THEOSCHOICE" == "AZURE_UBU" ]]; then
		INTERNALIP=$(ip addr show eth0 | grep 'inet ' | awk '{print $2}' | cut -d'/' -f1)
		sudo rm -f /opt/WHOAMI2 && sudo touch /opt/WHOAMI2 && sudo chmod 777 /opt/WHOAMI2 && echo "$INTERNALIP" | sudo tee -a /opt/WHOAMI2 > /dev/null
		
		SOFTVAL="Y"
		FILEVAL="Y"
		if ! which blobfuse2 >/dev/null || ! which blobfuse2 >/dev/null; then
		    SOFTVAL="N"
		fi
		if [ ! -d "/shiva/local/bucket" ] || [ ! -d "/shiva/global/bucket" ]; then
		    FILEVAL="N"
		fi		
		if [ "$SOFTVAL" = "N" ] || [ "$FILEVAL" = "N" ]; then
		    if [ -f /opt/EXEC1ON ]; then
			sleep 15
		    elif [ -f /opt/EXEC1DONE ]; then
			sudo mv /opt/EXEC1DONE /opt/EXEC1ON
		    fi
		    
		    sudo wget https://packages.microsoft.com/config/ubuntu/22.04/packages-microsoft-prod.deb && sudo dpkg -i packages-microsoft-prod.deb && sudo rm -f packages-microsoft-prod.deb && sudo apt-get update -y && sudo apt-get install libfuse3-dev fuse3 blobfuse2 cifs-utils jq -y
		    
		    /opt/EDN && sudo blobfuse2 mount all /shiva/global --config-file=/opt/globalSC.yaml && sudo blobfuse2 mount all /shiva/local --config-file=/opt/localSC.yaml && sudo mv /opt/EXEC1ON /opt/EXEC1DONE
		fi									
	fi
	
	if [[ "$THEOSCHOICE" == "E2E_UBU" ]]; then
		INTERNALIP=$(ip addr show eth1 | grep 'inet ' | awk '{print $2}' | cut -d'/' -f1)
		sudo rm -f /opt/WHOAMI2 && sudo touch /opt/WHOAMI2 && sudo chmod 777 /opt/WHOAMI2 && echo "$INTERNALIP" | sudo tee -a /opt/WHOAMI2 > /dev/null
	fi
	
	if [[ "$ELIGIBLEFORVPN" == "Y" ]]; then
		INTERNALIP2=$(ip addr show $STACKNAME | grep 'inet ' | awk '{print $2}' | cut -d'/' -f1)
		sudo rm -f /opt/WHOAMI3 && sudo touch /opt/WHOAMI3 && sudo chmod 777 /opt/WHOAMI3 && echo "$INTERNALIP2" | sudo tee -a /opt/WHOAMI3 > /dev/null		
	fi				
fi

if [[ "$OS" == "UBU" || "$OS" == "Ubuntu" ]]; then
    remove_locks
    terminate_processes
    remove_locks
    reconfigure_dpkg
    update_package_list
    echo "System is ready for package installation..."
    sudo rm -f /etc/apt/sources.list.d/docker.list
    sudo rm -f /etc/apt/keyrings/docker.gpg
    sudo apt-get remove -y docker docker-engine docker.io containerd runc
    sudo apt-get update -y
    sudo NEEDRESTART_MODE=a apt-get install -y ca-certificates curl gnupg
    sudo mkdir -m 0755 -p /etc/apt/keyrings
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
    echo 'deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu jammy stable' | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    sudo apt-get update -y
    sudo rm -rf /etc/glusterfs/glusterd.vol
    sudo NEEDRESTART_MODE=a apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin glusterfs-server glusterfs-client net-tools nfs-common cifs-utils jq wireguard socat whois
    sudo NEEDRESTART_MODE=a apt-get install -y tmux cron mysql-client
    sudo NEEDRESTART_MODE=a apt-get install -y s3fs
elif [[ "$OS" == "AZL" ]]; then
    #sudo yum remove -y docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine
    #sudo yum install -y yum-utils
    #sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
    #sudo yum update -y
    #sudo yum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin glusterfs-server glusterfs-client
    sudo yum remove -y docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine
    sudo yum install -y docker
elif [[ "$OS" == "ROCKY" || "$OS" == "ALMA" ]]; then
    sudo dnf remove -y docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-engine
    sudo dnf -y install dnf-plugins-core
    sudo dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
    sudo dnf install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin glusterfs-server glusterfs-client
fi

disable_selinux_temporary
disable_selinux_permanent

# Detect the package manager and disable other firewalls
if [ -f /etc/os-release ]; then
    . /etc/os-release
    case $ID in
        ubuntu)
            PKG_MANAGER="apt-get"
            echo "Disabling UFW and iptables..."
            sudo systemctl stop ufw
            sudo systemctl disable ufw
            sudo apt-get remove -y ufw
            sudo iptables -F
            ;;
        amzn)
            PKG_MANAGER="yum"
            echo "Disabling iptables..."
            sudo systemctl stop iptables
            sudo systemctl disable iptables
            sudo yum remove -y iptables-services
            ;;
        rocky|almalinux)
            PKG_MANAGER="dnf"
            echo "Disabling iptables..."
            sudo systemctl stop iptables
            sudo systemctl disable iptables
            sudo dnf remove -y iptables-services
            ;;
        *)
            echo "Unsupported OS"
            exit 1
            ;;
    esac

    # Install and configure firewalld
    if [[ "$THEOSCHOICE" == "E2E_UBU" ]]; then
	echo 'No Firewall'
    else
    	install_firewalld
    fi
    
    # Install Python3 and pip
    install_python

    echo "Setup completed successfully."
else
    echo "Cannot identify the OS."
    exit 1
fi

sudo mkdir -p $DOCKER_DATA_DIR
sudo chown -R root:docker $DOCKER_DATA_DIR
sudo chmod -R 755 $DOCKER_DATA_DIR

sudo mkdir -p $DFS_DATA_DIR
sudo chown -R root:root $DFS_DATA_DIR
sudo chmod -R 777 $DFS_DATA_DIR

sudo mkdir -p $DFS_CLUSTER_DIR
sudo chown -R root:root $DFS_CLUSTER_DIR
sudo chmod -R 777 $DFS_CLUSTER_DIR
sudo ln -s $DFS_CLUSTER_DIR /$STACKPRETTYNAME 

sudo mkdir -p $DFS_DATA2_DIR
sudo chown -R root:root $DFS_DATA2_DIR
sudo chmod -R 777 $DFS_DATA2_DIR

sudo mkdir -p $DFS_DATA2_DIR/$STACKNAME
sudo chown -R gluster:gluster $DFS_DATA2_DIR/$STACKNAME
sudo chmod -R 777 $DFS_DATA2_DIR/$STACKNAME

sudo mkdir -p $DFS_DATA2_DIR/Static$STACKNAME
sudo chown -R gluster:gluster $DFS_DATA2_DIR/Static$STACKNAME
sudo chmod -R 777 $DFS_DATA2_DIR/Static$STACKNAME

sudo mkdir -p $DFS_DATA_DIR/Portainer$STACKNAME
sudo chown -R gluster:gluster $DFS_DATA_DIR/Portainer$STACKNAME
sudo chmod -R 777 $DFS_DATA_DIR/Portainer$STACKNAME

sudo mkdir -p $DFS_DATA_DIR/PortainerMnt$STACKNAME
sudo chown -R root:root $DFS_DATA_DIR/PortainerMnt$STACKNAME
sudo chmod -R 777 $DFS_DATA_DIR/PortainerMnt$STACKNAME

sudo mkdir -p $DFS_DATA_DIR/Tmp$STACKNAME
sudo chown -R root:root $DFS_DATA_DIR/Tmp$STACKNAME
sudo chmod -R 777 $DFS_DATA_DIR/Tmp$STACKNAME

sudo mkdir -p $DFS_DATA_DIR/Errors$STACKNAME
sudo chown -R root:root $DFS_DATA_DIR/Errors$STACKNAME
sudo chmod -R 777 $DFS_DATA_DIR/Errors$STACKNAME

sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME
sudo chown -R root:root $DFS_DATA_DIR/Misc$STACKNAME
sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME

if [ "$TheReqRL" == "B" ] ; then
	sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME/webssh
	sudo chown -R root:root $DFS_DATA_DIR/Misc$STACKNAME/webssh
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh
	sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
	sudo chown -R root:root $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS		
fi

if [ "$TheReqRL" == "V" ] ; then
	if [[ "$CHITRAGUPTA" == "NA" ]]; then
		echo "Not Eligible For WebSSH"
	else
		sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME/webssh
		sudo chown -R root:root $DFS_DATA_DIR/Misc$STACKNAME/webssh
		sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh
		sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
		sudo chown -R root:root $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
		sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
		
		SetUpCHITRAGUPTA				
	fi		
fi

if [ "$TheReqRL" == "I" ] ; then
	sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME/RunHAProxy
	sudo chown -R root:root $DFS_DATA_DIR/Misc$STACKNAME/RunHAProxy
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/RunHAProxy

	sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME/webssh
	sudo chown -R $CURRENTUSER:$CURRENTUSER $DFS_DATA_DIR/Misc$STACKNAME/webssh
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh
	sudo mkdir -p $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
	sudo chown -R $CURRENTUSER:$CURRENTUSER $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh/PEMS
	sudo touch $DFS_DATA_DIR/Misc$STACKNAME/webssh/"$STACKPRETTYNAME"'backend.map'
	sudo chown $CURRENTUSER:$CURRENTUSER $DFS_DATA_DIR/Misc$STACKNAME/webssh/"$STACKPRETTYNAME"'backend.map'
	sudo chmod 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh/"$STACKPRETTYNAME"'backend.map'
	sudo chown -R $CURRENTUSER:$CURRENTUSER $DFS_DATA_DIR/Misc$STACKNAME/webssh
	sudo chmod -R 777 $DFS_DATA_DIR/Misc$STACKNAME/webssh
				
	create_error_files
	setup_http_server	
	
	if ! python3 -c "import PIL" &> /dev/null; then
	    echo "Pillow is not installed. Installing now..."
	    pip3 install Pillow
	else
	    echo "Pillow is already installed."
	fi
	sudo rm -f $DFS_DATA2_DIR/Static$STACKNAME/Logo$STACKNAME.png
	#cat /home/$CURRENTUSER/ImageMaker.py
	python3 /home/$CURRENTUSER/ImageMaker.py
	sudo rm -f /home/$CURRENTUSER/ImageMaker.py
	sudo rm -f /home/$CURRENTUSER/CoreFont.ttf
fi

sudo systemctl stop glusterd
sudo rm -rf /var/lib/glusterd/*
sudo rm -rf /etc/glusterfs/*
sudo rm -rf /var/log/glusterfs/*
sudo mkdir -p /etc/glusterfs && sudo rm -rf /etc/glusterfs/glusterd.vol
echo 'volume management
    type mgmt/glusterd
    option working-directory /var/lib/glusterd
    option transport-type socket
    option transport.socket.keepalive-time 10
    option transport.socket.keepalive-interval 2
    option transport.socket.read-fail-log off
    option transport.socket.listen-port 24007
    option ping-timeout 0
    option event-threads 1
#   option lock-timer 180
#   option transport.address-family inet6
    option base-port 49152
    option max-port  60999
end-volume' | sudo tee /etc/glusterfs/glusterd.vol

if [ -f /usr/sbin/glusterfs ]; then
	sudo systemctl restart glusterd
	sudo systemctl enable glusterd
fi

sudo mkdir -p /etc/docker && sudo rm -rf /etc/docker/daemon.json
if [ ! -f /opt/CLD ]; then
echo '{
  "data-root": "'"$DOCKER_DATA_DIR"'",
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "hosts": ["unix:///var/run/docker.sock"]
}' | sudo tee /etc/docker/daemon.json
else
echo '{
  "data-root": "'"$DOCKER_DATA_DIR"'",
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "hosts": ["unix:///var/run/docker.sock"]
}' | sudo tee /etc/docker/daemon.json
fi       
sudo usermod -a -G docker $CURRENTUSER

sudo rm -f /etc/systemd/system/docker.service
echo '[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=simple
ExecStart=/usr/bin/dockerd '"$TLSSTUFF"'--containerd=/run/containerd/containerd.sock
ExecReload=/bin/kill -s HUP $MAINPID
TimeoutSec=0
RestartSec=2
Restart=always
StartLimitBurst=3
StartLimitInterval=60s
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity
TasksMax=infinity
Delegate=yes
KillMode=process

[Install]
WantedBy=multi-user.target' | sudo tee /etc/systemd/system/docker.service > /dev/null

if [[ "$THEOSCHOICE" == "E2E_UBU" ]]; then
	echo 'No Firewall'
else
	sudo firewall-cmd --zone=public --add-port=$PortainerAPort/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=$PortainerSPort/tcp --permanent

	#sudo firewall-cmd --zone=public --add-port=$VarahaPort1/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=$VarahaPort2/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=$VarahaPort3/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=$VarahaPort4/tcp --permanent

	sudo firewall-cmd --zone=public --add-port=$BDDPort1/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=$BDDPort2/tcp --permanent
	
	sudo firewall-cmd --zone=public --add-port=$websshPort1/tcp --permanent	

	sudo firewall-cmd --zone=public --add-port=2377/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=7946/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=7946/udp --permanent
	sudo firewall-cmd --zone=public --add-port=4789/udp --permanent
	sudo firewall-cmd --zone=public --add-port=53/udp --permanent

	sudo firewall-cmd --zone=public --add-port=111/udp --permanent
	sudo firewall-cmd --zone=public --add-port=111/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=24007/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=24008/tcp --permanent
	#sudo firewall-cmd --zone=public --add-port=49152-60999/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=35000-65000/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=35000-65000/udp --permanent

	sudo firewall-cmd --zone=public --add-protocol=50 --permanent

	sudo firewall-cmd --zone=public --add-port=16746-19478/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=2049/tcp --permanent
	sudo firewall-cmd --zone=public --add-port=53/tcp --permanent
		        
	sudo firewall-cmd --reload
fi

if [ ! -f /opt/CLD ]; then
    echo 'Firewall On'
else
    if [[ "$THEOSCHOICE" == "E2E_UBU" ]]; then
        echo 'No Firewall'
    else
        sudo systemctl stop firewalld
        sudo systemctl disable firewalld
    fi
fi

sudo systemctl daemon-reload
sudo systemctl enable docker
sudo systemctl restart docker

install_minio

#if [ "$TheReqRL" == "I" ] ; then
#	create_webssh_router_support_files
#fi
#if [ "$TheReqRL" == "B" ] ; then
#	create_webssh_manager_support_files
#fi

sudo rm -rf /home/$CURRENTUSER/.ssh/known_hosts
sudo rm -rf /root/.ssh/known_hosts
sudo rm -rf /root/.bash_history
sudo rm -rf /home/$CURRENTUSER/.bash_history

sudo rm -f /home/$CURRENTUSER/SetUpHosts.sh
sudo rm -f /home/$CURRENTUSER/SetUpDocker.sh

sudo touch /opt/DSUDONE$STACKNAME
sudo chmod 777 /opt/DSUDONE$STACKNAME
sudo mv /home/$CURRENTUSER/DSULog$STACKNAME.out /opt/DSULog$STACKNAME.out
sudo chmod 777 /opt/DSULog$STACKNAME.out

